{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook details process of pulling Treasury curve data from the Federal Reserve API (FRED).\n",
    "<br><br>\n",
    "Requires one to register for an <a target=\"_blank\" href=\"https://research.stlouisfed.org/docs/api/api_key.html\">API key</a>.<br>\n",
    "For simplicity, using an external package (<a target=\"_blank\" href=\"https://github.com/mortada/fredapi\">fredapi</a>),\n",
    "which requires separate installation.  It's a simple urllib wrapper around the Fed's root API <a target=\"_blank\" href=\"https://api.stlouisfed.org/fred\">endpoint</a>.\n",
    "<br>\n",
    "You could also just <a target=\"_blank\" href=\"http://docs.python-requests.org/en/master/\">query</a> the API directly as well.\n",
    "<br><br>\n",
    "Any other data feed, including <a target=\"_blank\" href=\"https://www.bloomberg.com/professional/solution/bloomberg-terminal/\">Bloomberg</a>, <a target=\"_blank\" href=\"https://financial.thomsonreuters.com/en/products/infrastructure/trading-infrastructure/fintech-digital-solutions/financial-data-api-delivery.html\">Reuters</a>, or <a target=\"_blank\" href=\"https://www.quandl.com/\">Quandl</a>, should work just fine.\n",
    "<br>\n",
    "The goal is just to compile historical recordings of various segments of the Treasury curve.\n",
    "<br>\n",
    "The process below caches the pulled results on disk in the repo's /data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package versioning\n",
      "------------\n",
      "pandas:  0.20.3\n",
      "numpy:  1.13.3\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "print('package versioning')\n",
    "print ('------------')\n",
    "# standard library\n",
    "import datetime\n",
    "\n",
    "#external\n",
    "import pandas as pd\n",
    "print('pandas: ', pd.__version__)\n",
    "import numpy as np\n",
    "print('numpy: ', np.__version__)\n",
    "from fredapi import Fred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pull data from Federal Reserve API (FRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# supply authorization creds\n",
    "key = ''  #  <----- set API key here\n",
    "fred = Fred(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify target variables | ticker/titles as provided by the Federal Reserve Bank of St. Louis (FRED)\n",
    "pulldict = {\n",
    "'FEDFUNDS':'Effective Federal Funds Rate',\n",
    "'DGS1MO':'1-Month Treasury Constant Maturity Rate',\n",
    "'DGS3MO':'3-Month Treasury Constant Maturity Rate',\n",
    "'DGS6MO':'6-Month Treasury Constant Maturity Rate',    \n",
    "'DGS1':'1-Year Treasury Constant Maturity Rate',\n",
    "'DGS2':'2-Year Treasury Constant Maturity Rate',\n",
    "'DGS3':'3-Year Treasury Constant Maturity Rate',\n",
    "'DGS5':'5-Year Treasury Constant Maturity Rate',\n",
    "'DGS7':'7-Year Treasury Constant Maturity Rate',\n",
    "'DGS10':'10-Year Treasury Constant Maturity Rate',\n",
    "'DGS20':'20-Year Treasury Constant Maturity Rate',\n",
    "'DGS30':'30-Year Treasury Constant Maturity Rate'  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEDFUNDS Effective Federal Funds Rate | \n",
      "DGS1MO 1-Month Treasury Constant Maturity Rate | \n",
      "DGS3MO 3-Month Treasury Constant Maturity Rate | \n",
      "DGS6MO 6-Month Treasury Constant Maturity Rate | \n",
      "DGS1 1-Year Treasury Constant Maturity Rate | \n",
      "DGS2 2-Year Treasury Constant Maturity Rate | \n",
      "DGS3 3-Year Treasury Constant Maturity Rate | \n",
      "DGS5 5-Year Treasury Constant Maturity Rate | \n",
      "DGS7 7-Year Treasury Constant Maturity Rate | \n",
      "DGS10 10-Year Treasury Constant Maturity Rate | \n",
      "DGS20 20-Year Treasury Constant Maturity Rate | \n",
      "DGS30 30-Year Treasury Constant Maturity Rate | \n"
     ]
    }
   ],
   "source": [
    "# iterate through dictionary, request data and construct pd dataframe\n",
    "import time\n",
    "df = pd.DataFrame()\n",
    "for pull_ticker in pulldict.keys():\n",
    "    data_pull = pull_ticker\n",
    "    description = pulldict[pull_ticker]\n",
    "    print(data_pull, description, '| ',end='\\n')\n",
    "    tmp_df = fred.get_series_latest_release(data_pull)\n",
    "    tmp_df = pd.DataFrame(tmp_df)\n",
    "    tmp_df.rename(columns={list(tmp_df.columns.values)[0]: description}, inplace=True)\n",
    "    df = df.join(tmp_df, how='outer')\n",
    "    time.sleep(0.5)  # intentionally time-space requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename & order df columns\n",
    "current_col_list = ['Effective Federal Funds Rate','1-Month Treasury Constant Maturity Rate','3-Month Treasury Constant Maturity Rate','6-Month Treasury Constant Maturity Rate','1-Year Treasury Constant Maturity Rate','2-Year Treasury Constant Maturity Rate','3-Year Treasury Constant Maturity Rate','5-Year Treasury Constant Maturity Rate','7-Year Treasury Constant Maturity Rate','10-Year Treasury Constant Maturity Rate','20-Year Treasury Constant Maturity Rate','30-Year Treasury Constant Maturity Rate']\n",
    "new_col_list = ['FEDFUNDS','DGS1MO','DGS3MO','DGS6MO','DGS1','DGS2','DGS3','DGS5','DGS7','DGS10','DGS20','DGS30']\n",
    "for x in range(0,len(new_col_list)):\n",
    "    df.rename(columns={'{0}'.format(current_col_list[x]): '{0}'.format(new_col_list[x])}, inplace=True)\n",
    "df = df[new_col_list]\n",
    "# rename index column\n",
    "df.index.names = ['date']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all columns have daily frequency except FEDFUNDS, which is monthly | ffill column to ensure existing/latest month is graphed\n",
    "df['FEDFUNDS'] = df['FEDFUNDS'].fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # optional:  [basic plot of data pulled]\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# for col_x in df.columns.values:\n",
    "#     df[col_x].dropna().plot(color='black',alpha=0.6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### truncate dataset\n",
    "** DGS30: considerable missing data between 2002-2009\n",
    "** DGS1MO: first obs 2007-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set earliest period to 2006\n",
    "sdate = '2006-02-09'\n",
    "sdate = np.datetime64(sdate)\n",
    "edate = np.datetime64(str(datetime.datetime.now().date()))\n",
    "df = df.truncate(before=sdate, after=edate).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attempt to fill NaNs w/ ffill only\n",
    "for col_x in df.columns.values:\n",
    "    df[col_x] = df[col_x].fillna(method='ffill',limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resample to monthly observations | median\n",
    "df_daily_biz = df.resample('B').median().copy()\n",
    "df_weekly = df.resample('W').median().copy()\n",
    "df_monthly = df.resample('M').median().copy()\n",
    "df_quarterly = df.resample('Q').median().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3048\n",
      "611\n",
      "141\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(df_daily_biz))\n",
    "print(len(df_weekly))\n",
    "print(len(df_monthly))\n",
    "print(len(df_quarterly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# ensure no missing values exist\n",
    "check_null = df_monthly.isnull().sum(axis=0).sort_values(ascending=False)/float(len(df))\n",
    "print(np.sum(check_null) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### cache df objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### cache data | keep index\n",
    "df_daily_biz.to_csv('data/historical_data_daily.csv')\n",
    "df_weekly.to_csv('data/historical_data_weekly.csv')\n",
    "df_monthly.to_csv('data/historical_data_monthly.csv')\n",
    "df_quarterly.to_csv('data/historical_data_quarterly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
